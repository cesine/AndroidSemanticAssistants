%% Semantic Assistants Documentation
%% 
%% This file is part of the Semantic Assistants architecture.
%%
%% Copyright (C) 2009, 2010, 2011 Semantic Software Lab, http://www.semanticsoftware.info
%%
%% The Semantic Assistants architecture is free software: you can
%% redistribute and/or modify it under the terms of the GNU Affero General
%% Public License as published by the Free Software Foundation, either
%% version 3 of the License, or (at your option) any later version.
%% 
%% This program is distributed in the hope that it will be useful,
%% but WITHOUT ANY WARRANTY; without even the implied warranty of
%% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%% GNU Affero General Public License for more details.
%% 
%% You should have received a copy of the GNU Affero General Public License
%% along with this program.  If not, see <http://www.gnu.org/licenses/>.
%%

\chapter{The \sa Server}
\label{chap:serv}
Semantic NLP services are executed by a Semantic Assistants
server. You can either use an existing server (e.g., from your
company's or university's intranet, or a public server) or run you own
server locally. To access to an existing server, you need to know it's
hostname and port, which are then configured in the client plug-ins
through a preference window.  If you want to run your own server using
the included example NLP services, follow the instructions below.

\section{Starting the Server}
Type \texttt{ant run} in the \url{SemanticAssistants/Server} directory
to start the server. Please refer to Section~\ref{sec:inst-comp} for
more installation and compilation details. The server will
automatically load all available OWL service descriptions from the
default location \url{Resources/OwlServiceDescriptions} and publish
these to the clients.

\subsection{Configuring the Server User Request Limit}
To configure the server to limit the amount of user requests it will
process concurrently, one needs to modify the \texttt{server.thread.allowed}
found in \url{SemanticAssistants/SemassistProperties.xml};  The default
value is already set but if ommitted the number of threads that will
be allowed will not necessarily reflect the server capabilities.

\subsection{Configuring the Server Fixed Pipelines}
The server comes with the possibility to set the number of concurrent threads
of the same pipeline (see GATE documentation for pipeline definition).  To 
configure these settings, one must modfiy/add the following lines
\begin{enumerate}
\item \texttt{server.pipeline.\#.name}
\item \texttt{server.pipeline.\#.number.pooled}
\item \texttt{server.pipeline.\#.startup}
\item \texttt{server.pipeline.\#.fullpath}
\end{enumerate}
(**note: the '\#' must be replaced by a valid positive integer value)
These lines refer to the pipeline that will be pooled for concurrent and
speedier access.  
"name" refers to the name of the pipeline as indicated by the contents of the .xgapp file.
"number.pooled" refers to the number of threads we have allocated for this pipeline.
"startup" indicated by a "true"/"false" string value which loads or ignores the pipeline at server startup.
"fullpath" refers to the location of the xgapp file that will be used to load the pipeline.
These properties must be grouped and must be a set when being used in the \url{SemanticAssistants/SemassistProperties.xml};
These properties can be omitted if desired and only the \texttt{server.thread.allowed} will be taken into account
One must be aware that the number of pipelines set in \texttt{server.pipeline.\#.number.pooled}
will be substracted from the \texttt{server.thread.allowed} property.  Should the number previously
set in \texttt{server.thread.allowed} not be sufficient, the server will automatically resize the property
to contain the total number of threads needed.

\subsection{Testing the Server by accessing the WSDL}
To test if the Server is operating open your favourite browser and
paste \url{http://<server host>:<server port>/SemAssist?wsdl} (Note
the \texttt{<server host>} has a default value of the local machine
name and the \texttt{<server port>} is the value of the property
\texttt{server.port.wsdl} found in
\url{SemanticAssistants/SemassistProperties.xml}; by default it is set
to 8879.

On most platforms, either \url{http://localhost:8879/SemAssist?wsdl}
or \url{http://127.0.0.1:8879/SemAssist?wsdl} should show you the WSDL
if the server has been initialized correctly.\footnote{If this does
  not work, try substituting the current IP address for
  localhost/127.0.0.1 and check that the port is not blocked by a
  firewall.}

\subsection{Server Testing using the Command Line Client}
To test if the server is running correctly and can be accessed from
the clients, we recommend you run some tests using the command-line
client described in Section~\ref{sec:sacl:clc}.


\section{Integrating New NLP Services}
\label{sec:nlpservices}
For the server to know how to handle the different NLP services
offered through the architecture, it needs a \emph{description} of
each offered service. These are by default located in the
\url{SemanticAssistants/Resources/OwlServiceDescriptions}
directory. The GATE pipelines corresponding to these service
descriptions are located (by default) in
\url{Resources/GatePipelines}. The language service descriptions are
ontologies, building on the \emph{SemanticAssistants.owl} ontology,
which, in turn, extends the \emph{ConceptUpper.owl} ontology. Both of
these are located in \url{ont-repository} under
\url{SemanticAssistants/Resources}.

The details for developing new NLP service descriptions are covered in
Chapter~\ref{chap:services}.  In order to create a new language
service description, it is often easier to copy an old one and edit
it. Prot\'{e}g\'{e}\footnote{Prot\'{e}g\'{e},
  \url{http://protege.stanford.edu}} is helpful as an ontology
editor. Most important is to define the parameters that can be passed
to this language service, as well as the description of the results
that should be passed back to the client.

In summary, to integrate a new NLP service, two steps are necessary:
\begin{enumerate}
\item Store the GATE pipeline implementing the service under
  \url{Resources/GatePipelines} (using GATE's \emph{Save Application State}
  or \emph{Export to Teamware} menu functions).
\item Develop an OWL service description for this pipeline.  For
  details on the OWL NLP description format, please refer to
  Section~\ref{sec:owl}.
\end{enumerate}
